---
title: "Normalization of the vams vs intraveneous untargeted metabolomics data, negative polarity"
author: "Christa Malfertheiner, Johannes Rainer, Giuseppe Paglia and Sigurdur Smarason"
graphics: yes
output:
  BiocStyle::html_document:
    toc_float: true
bibliography: references.bib
csl: biomed-central.csl
references:
- id: dummy
  title: no title
  author:
  - family: noname
    given: noname
---

```{r biocstyle, echo = FALSE, results = "asis"}
library(BiocStyle)
BiocStyle::markdown()
```

**Modified**: `r file.info("vams_normalization_neg.Rmd")$mtime`<br />
**Compiled**: `r date()`

```{r settings, echo = FALSE, results = "hide", message = FALSE}
## Set general options
options(useFancyQuotes = FALSE)
set.seed(123)

## Setting golden ratio to save images
phi <- (1+sqrt(5))/2

## Define paths:
filename <- "vams_normalization_neg"
## Path to save the images; remove all old images.
## IMAGE_PATH <- paste0("C:/Users/User/Documents/Masterarbeit/R/images/", filename, "/")
IMAGE_PATH <- paste0("images/", filename, "/")
dir.create(IMAGE_PATH, recursive = TRUE, showWarnings = FALSE)
## Path to store RData files
RDATA_PATH <- paste0("data/RData/", filename, "/")
if (!file.exists(RDATA_PATH)) dir.create(RDATA_PATH, recursive = TRUE)

## Define the path where we can find the mzML files:
## MZML_PATH <- "/data/massspec/mzML/"
MZML_PATH <- "C:/Users/User/Documents/mzML_neg"
if (!file.exists(MZML_PATH))
    stop("Can not find the directory with the mzML files: ", MZML_PATH)

## Get the number of cpus allocated or fall back to 3 
ncores <- as.integer(Sys.getenv("SLURM_JOB_CPUS_PER_NODE", 4)) - 1L
```

# Introduction

In this document we perform the normalization of the feature abundances of the
*MitYOU* project for the negative polarity. The preprocessing of the data is
described in file *vams_preprocessing_neg.Rmd*. For the evaluation of different
normalization methods and details on the employed normalization approach please
see *vams_normalization.Rmd*.


# Data import and initial quality assessment

Below we load all libraries required for the analysis and the data. We also
fill-in missing peak values, i.e. for features for which not a peak was
identified in all samples, we integrate the signal from the feature area in
these samples. 

```{r libraries-data, message = FALSE}
library(xcms)
library(RColorBrewer)
library(pander)
library(SummarizedExperiment)

## register(bpstart(MulticoreParam(ncores)))
library(doParallel)
#registerDoParallel(ncores)
register(DoparParam(), default = TRUE)
library(CompMetaboTools)

## Load utility functions for this document
## source("util-functions.R")
## source("vams_normalization_functions.R")

## Define colors for the groups.
col_source <- brewer.pal(5, name = "Set1")
names(col_source) <- c("RBC",           #' red
                       "plasma",        #' blue
                       "all",           #' green
                       "capillary",     #' purple
                       "venous")        #' orange

load("data/RData/vams_preprocessing_neg/data_neg.RData")
data_neg$batch <- factor(data_neg$batch)

```

Next we extract the feature abundances as a `SummarizedExperiment`, subsetting
also to the features defined above.

```{r extract-as-se}
res_neg <- quantify(data_neg, method = "sum", filled = FALSE)

```

# Gap filling and imputation of missing values

Next we fill-in data for samples in which no peak was detected. While we will
eventually exclude filled-in signals in the estimation of the normalization
factors for the within and between-batch normalization, we will normalize these
intensities as they might be affected by the same effects than the *real*
signal. Imputation of signals that are still missing after filling-in will be
performed **after** normalization.

Below we fill-in missing peak data from an m/z - retention time slice defined by
the m/z range of the feature and the retention time window of the feature
definition that is extended by a constant value, the median retention time width
of all identified peaks. The retention time window from which the signal is
integrated should be expanded, because the feature's retention time range
represents the minimal and maximal apex position of the associated peaks in the
time dimension, and is thus unrelated to the actual retention time width of the
peaks. The m/z range is also extended by 20ppm.

```{r fill-in, message = FALSE, warning = FALSE, eval = !file.exists(paste0(RDATA_PATH, "data_neg_filled.RData"))}
## Fill-in missing values
data_neg <- fillChromPeaks(data_neg, param = ChromPeakAreaParam())
save(data_neg, file = paste0(RDATA_PATH, "data_neg_filled.RData"))

```

```{r load, message = FALSE}
load(paste0(RDATA_PATH, "data_neg_filled.RData"))

## Add filled-in data to the result object
assays(res_neg)$raw_filled <- featureValues(data_neg, method = "sum",
                                            filled = TRUE)
## Add the only-filled-in signal to the result object
tmp <- assay(res_neg, "raw_filled")
tmp[!is.na(assay(res_neg, "raw"))] <- NA
assays(res_neg)$raw_only_filled <- tmp

```


Below we compare the signal distribution of detected and filled-in peak signals.

```{r compare-detected-filled-plot, fig.path = IMAGE_PATH, message = FALSE, echo = FALSE, warning = FALSE, fig.cap = "Distribution of (log2) signal intensities of detected and filled-in peaks. Left: all features/peaks, right: only peaks of features used in the present analysis based on the above definition.", fig.width = 8, fig.height = 4}
## Distribution raw data
ints_det <- chromPeaks(data_neg)[!chromPeakData(data_neg)$is_filled, "into"]
ints_fil <- chromPeaks(data_neg)[chromPeakData(data_neg)$is_filled, "into"]

par(mfrow = c(1, 2), mar = c(4, 4.5, 4, 0.5))
boxplot(list(detected = log2(ints_det), filled = log2(ints_fil)),
        varwidth = TRUE, main = "all peaks",
        ylab = expression(log[2]~abundance))

## Peaks assigned to features
pk_idxs <- sort(unlist(featureDefinitions(data_neg)[, "peakidx"]))
tmp <- chromPeaks(data_neg)[pk_idxs, "into"]
ints_det <- tmp[!chromPeakData(data_neg)$is_filled[pk_idxs]]
ints_fil <- tmp[chromPeakData(data_neg)$is_filled[pk_idxs]]
boxplot(list(detected = log2(ints_det), filled = log2(ints_fil)),
        varwidth = TRUE, main = "feature peaks",
        ylab = expression(log[2]~abundance))

```

As expected, abundances from filled-in peaks have on average lower intensities
than truly detected peaks. Abundances are however relatively similar suggesting
that for many missing peaks a signal from an ion was recorded, but peak
detection failed.

Afterwards, we compare the filled-in with the detected signal for *QC samples*. 
We start by calculating the mean of both, then we proceed with plotting the results.
Ideally, the plotted dots should be found along the diagonal `y = x` 
(maximum correlation). Also, we compute the Pearson's correlation coefficient,
specifying `use = "pairwise.complete.obs"`: this string is used to make explicit
how to handle missing data, in this case calculating the correlation only using
all complete pairs of values. Ideally, the filled-in signal should be correlated
to the detected signal.

```{r correlation-filled-detected, fig.path = IMAGE_PATH, fig.cap = "Correlation of per-feature averaged detected and filled-in signal in QC samples.", echo = FALSE}
avg_det <- rowMeans(assay(res_neg, "raw")[, res_neg$sample == "POOL"],
                    na.rm = TRUE)
avg_fil <- rowMeans(assay(res_neg, "raw_only_filled")[, res_neg$sample == "POOL"],
                    na.rm = TRUE)
plot(log2(avg_det), log2(avg_fil), xlab = "detected", ylab = "filled-in",
     main = "Feature abundances, QC samples", pch = 16, col = "#00000080")
abline(0, 1, col = "grey")
cor(log2(avg_det), log2(avg_fil), use = "pairwise.complete.obs")

```

We can see a relatively high correlation between the detected and filled-in
signal, especially for features with higher abundances. For low abundant
features (below ~ 1000) detected abundances are systematically higher than
filled-in.

We now calculate and compare for each feature in QC samples the difference
between the detected and filled-in peak data. Evaluation in QC samples avoids
any potential differences being caused by biological differences of the compared
samples.

First, we plot the detected data:

```{r raw-boxplot-detected, fig.path =IMAGE_PATH, fig.height = 7, fig.width = 7 * phi, fig.cap = "Number of features and log2 abundance of raw detected data.", echo = FALSE}
dobox <- function(x,
                  col = paste0(col_source[as.character(data_neg$source)], "ff"),
                  outline = FALSE, notch = TRUE, range = 0,
                  border = paste0(col_source[as.character(data_neg$source)], "60"),
                  ylab = expression(log[2]~abundance), xaxt = "n", xlab = "",
                  ...) {
    boxplot(x, col = col, outline = outline, notch = notch, range = range,
            border = border, ylab = ylab, xaxt = xaxt, xlab = xlab, ...)
    grid(nx = NA, ny = NULL)
}

layout(mat = matrix(1:2, ncol = 1), height = c(0.3, 0.7))
cols <- col_source[as.character(res_neg$source)]
par(mar = c(0.2, 4.5, 2, 0.5))
barplot(apply(assay(res_neg, "raw"), MARGIN = 2, function(x) sum(!is.na(x))),
        col = paste0(cols, 80), ylim = c(0, 12000),
        ylab = "Features", xaxt = "n", main = "Detected raw data")
legend("top", horiz = TRUE, col = col_source, legend = names(col_source), lwd = 1)
par(mar = c(0.2, 4.5, 0, 0.5))
dobox(log2(assay(res_neg, "raw")), col = paste0(cols, "ff"), xaxt = "n",
      border = paste0(cols, 60))
points(colMeans(log2(assay(res_neg, "raw")), na.rm = TRUE), type = "l")
grid(nx = NA, ny = NULL)

```

In the plot above, we find the samples with lower intensity signals that we
also found in the preprocessing step: in these samples considerably less peaks
were identified; the mean intensity of these samples, though, is comparable to
that of the others.

Plasma samples (blue) have less valid values for features compared to samples
from other sources. Some of the RBC (red) samples also have a considerably lower
number of detected features. The distribution of feature intensities seems to
be comparable between samples, sources and batches. The high similarity of
average abundances between samples visible above might however be misleading,
since only signal from identified peaks are considered. Comparing signal
intensities **after** filling-in missing peak data might be better, because it
also reflects the fact that some features are simply not present in the data.

Next, we show the filled-in values:

```{r raw-boxplot-only-filled, fig.path = IMAGE_PATH, fig.height = 7, fig.width = 7 * phi, fig.cap = "Number of features and log2 abundance of filled-in data.", message = FALSE, echo = FALSE}
layout(mat = matrix(1:2, ncol = 1), height = c(0.3, 0.7))
cols <- col_source[as.character(res_neg$source)]
par(mar = c(0.2, 4.5, 2, 0.5))
barplot(apply(assay(res_neg, "raw_only_filled"), MARGIN = 2,
              function(x) sum(!is.na(x))),
        col = paste0(cols, 80), ylim = c(0, 12000),
        ylab = "Features", xaxt = "n", main = "Filled-in raw data")
legend("top", horiz = TRUE, col = col_source, legend = names(col_source), lwd = 1)
par(mar = c(0.2, 4.5, 0, 0.5))
dobox(log2(assay(res_neg, "raw_only_filled")), col = paste0(cols, "ff"),
      xaxt = "n", border = paste0(cols, 60))
points(colMeans(log2(assay(res_neg, "raw_only_filled")), na.rm = TRUE),
       type = "l")
grid(nx = NA, ny = NULL)

```

We can see that there is a higher number of rescued signals in the ambiguous
samples: this indicates that a low intensity signal was probably not detected or
discarded during the course of peak detection. In this case, it is observed that
the mean abundance of these samples is lower than that of the others; this is
expected and consistent with the boxplots showed above (lower intensity for
filled-in signals).

After filling in missing peak values the proportion of detected features is
highly comparable between samples, but more differences between abundances are
visible. Plasma samples (blue) show however considerably lower signal
intensities than all other samples, which reflects that less peaks were detected
for these features in these samples (and intensities were thus filled-in).

Next we create relative log abundance plots that represent the difference of the
(log) abundances of each feature in a sample compared to the median abundance of
that feature in samples from the same sample group (source).

Finally, we plot the complete data set (detected and filled-in signals):

```{r raw-boxplot-all, fig.path = IMAGE_PATH, fig.height = 7, fig.width = 7 * phi, fig.cap = "Number of features and log2 abundance of detected and filled-in data.", message = FALSE, echo = FALSE}
layout(mat = matrix(1:2, ncol = 1), height = c(0.3, 0.7))
cols <- col_source[as.character(res_neg$source)]
par(mar = c(0.2, 4.5, 2, 0.5))
barplot(apply(assay(res_neg, "raw_filled"), MARGIN = 2,
              function(x) sum(!is.na(x))),
        col = paste0(cols, 80), ylim = c(0, 20000),
        ylab = "Features", xaxt = "n", main = "Detected and filled-in raw data")
legend("top", horiz = TRUE, col = col_source, legend = names(col_source), lwd = 1)
par(mar = c(0.2, 4.5, 0, 0.5))
dobox(log2(assay(res_neg, "raw_filled")), col = paste0(cols, "ff"), xaxt = "n",
      border = paste0(cols, 60))
points(colMeans(log2(assay(res_neg, "raw_filled")), na.rm = TRUE), type = "l")
grid(nx = NA, ny = NULL)

```

From this image, we can conclude that most of the missing signals have been
rescued during the gap-filling step: the number of features, in fact, is
comparable among all samples, though a significant signal deficiency is still
observed in the 7 samples seen before.

We also plot the Relative Log Abundance (RLA) values for the raw data and for
data after gap filling; these will be later used to assess the efficiency of
normalization.

```{r raw-rla-plot, fig.path = IMAGE_PATH, fig.height = 7, fig.width = 7 * phi, fig.cap = "Relative Log Abundance (RLA) of raw data compared to the filled-in data.", echo = FALSE}
## RLA of raw data
par(mfrow = c(2, 1), mar = c(0.2, 4.5, 4.5, 0.5))
boxplot(xcms::rowRla(assay(res_neg, "raw"), group = res_neg$source),
        cex = 0.5, pch = 16, col = col_source[as.character(res_neg$source)],
        border = paste0(col_source[as.character(res_neg$source)], 40),
        notch = TRUE, outline = FALSE, ylim = c(-6, 4),
        main = "Raw data", xaxt = "n", ylab = "RLA")
grid(nx = NA, ny = NULL)
## RLA after filling-in missing data
boxplot(xcms::rowRla(assay(res_neg, "raw_filled"), group = res_neg$source),
        cex = 0.5, pch = 16, col = col_source[as.character(res_neg$source)],
        border = paste0(col_source[as.character(res_neg$source)], 40),
        notch = TRUE, outline = FALSE,
        main = "Filled-in data", xaxt = "n", ylab = "RLA")
grid(nx = NA, ny = NULL)

```

The RLA plot showing the raw data indicates some potentially systematic drifts
in signal intensities that includes also consistently lower average RLA values
in the last samples from the first, and consistently higher average RLA values
in the last samples from the second batch. Next we plot the RLA plots after
filling-in missing peak data.

The RLA plots after filling-in missing peak data look similar but the trends
become more pronounced.


## Internal standards

Internal standards are chemical species that resemble molecules in a sample, but
they have a distinct characteristic that helps us discriminate them from the
metabolites of interest (i.e. these internal standards are artificially modified
metabolites not occurring in a normal human sample). Internal standards are
added in the sample mix before data acquisition.

In the chunk code below, we load the table with the internal standards and their
expected mass-to-charge ratio m/z. Features detected at these m/z that also have
a retention time within a range of 30 seconds from the internal standard of
reference are then identified and their ID is added to the table.

```{r internal-standards-read, message = FALSE, warning = FALSE}
library(Rdisop)
library("MetaboCoreUtils")
is_info <- read.table(
    "https://raw.githubusercontent.com/EuracBiomedicalResearch/lcms-standards/master/data/internal_standards.txt",
    sep = "\t", header = TRUE, as.is = TRUE)
is_info <- is_info[!is.na(is_info$NEG), ]
is_info$class <- "IS"
is_info$mzneut = NA
is_info$mz_ion = NA
for (i in seq(nrow(is_info))) {
    if (grepl("C", is_info$formula[i]))
        is_info$mzneut[i] <- getMolecule(is_info$formula[i])$exactmass
    else
        is_info$mzneut[i] = as.numeric(is_info$formula[i])
    #' Calculate also the m/z
    is_info$mz_ion[i] <- mass2mz(is_info$mzneut[i],
                                 adduct = is_info$NEG[i])[1, 1]
}
is_info <- is_info[!is.na(is_info$mz_ion), ]

```


We plot now the EIC for each identified internal standard:

```{r internal-standards-plot, echo = FALSE, message = FALSE, warning = FALSE}
#' For each internal standard, try to find features that overlap the m/z
#' and are close to the expected retention time.
rt_tol <- 30
is_info$feature_id <- NA_character_
for (i in seq_len(nrow(is_info))) {
    fts <- featureDefinitions(data_neg, mz = is_info$mz_ion[i], ppm = 10)
    if (nrow(fts)) {
        rtdiff <- abs(fts$rtmed - is_info$RT[i])
        keep <- rtdiff < rt_tol
        if (sum(keep) == 1)
            is_info$feature_id[i] <- rownames(fts)[keep]
    }
}
is_info <- is_info[!is.na(is_info$feature_id), ]

is_info_features <- featureChromatograms(
    data_neg, features = is_info$feature_id, expandRt = 5)

#' Plot the features for the internal standards.
col <- col_source[as.character(data_neg$source)]

dr <- paste0(IMAGE_PATH, "internal-standards/")
dir.create(dr, showWarnings = FALSE)
for (i in seq_len(nrow(is_info))) {
    fn <- gsub("%", "", paste0(dr, "IS_", is_info[i, "name"], "_NEG.png"))
    chr <- is_info_features[i, ]
    cls <- col[chromPeaks(chr)[, "sample"]]
    png(fn, width = 16, height = 8, units = "cm", res = 200, pointsize = 4)
    plot(chr, peakBg = paste0(cls, 20),
         main = paste0(is_info$name[i], ": ",
                       format(mz(chr)[1], digits = 6), "-",
                       format(mz(chr)[2], digits = 6)),
         peakCol = paste0(cls, 60))
    abline(v = is_info$RT[i], lty = 2)
    dev.off()
}

```

All features possibly related to internal standards (i.e. with a matching m/z
and a retention time within 30 seconds to the expected one) have been manually
evaluated and only features have been assigned to internal standards if the
signal was unambiguous. Some features for internal standards have been removed
if a very strong matrix dependent intensity difference was apparent.

We create two subsets of internal standards, one with *problematic* ones according
to the created plots (these show very strong matrix-specific differences) and
the other with the *good* ones.


```{r subsetting IS}
is_std_prob <- subset(
    is_info, is_info$name %in% c("L-Cystine (13C6, 99%; 15N2, 99%)",
                                 "L-Methionine (13C5, 99%; 15N, 99%)",
                                 "L-Phenylalanine (13C9, 99%; 15N, 99%)",
                                 "L-Proline (13C5, 99%; 15N, 99%)",
                                 "L-Aspartic acid (13C4, 99%; 15N, 99%)",
                                 "L-Serine (13C3, 99%; 15N, 99%)",
                                 "L-Tyrosine (13C9, 99%; 15N, 99%)"))
is_std = subset(
    is_info, is_info$name %in% c("L-Arginine HCl (13C6, 99%; 15N4, 99%)",
                                 "L-Glutamic acid (13C5, 99%; 15N, 99%)",
                                 "L-Histidine HCl H2O (13C6; 15N3, 99%)",
                                 "L-Lysine 2HCl (13C6, 99%; 15N2, 99%)",
                                 "L-Threonine (13C4, 99%; 15N, 99%)"))

```

The table below lists the problematic and unproblematic internal standards and 
their assigned feature with mean abundance and its standard deviation.

```{r, echo = FALSE, results = "asis"}
#' table of internal standards with mean and sd of abundances (in log2 scale)
tmp_fv <- assay(res_neg, "raw")[is_std$feature_id, ]
is_std$mean_abd <- rowMeans(log2(tmp_fv), na.rm = TRUE)
is_std$sd_abd <- rowSds(log2(tmp_fv), na.rm = TRUE)
is_std$RSD <- rowRsd(tmp_fv, na.rm = TRUE)

pandoc.table(is_std[, c("name", "mean_abd", "sd_abd", "RSD")],
             style = "rmarkdown", caption = "*Good* internal standards.")

```

```{r, echo = FALSE, results = "asis"}
tmp_fv <- assay(res_neg, "raw")[is_std_prob$feature_id, ]
is_std_prob$mean_abd <- rowMeans(log2(tmp_fv), na.rm = TRUE)
is_std_prob$sd_abd <- rowSds(log2(tmp_fv), na.rm = TRUE)
is_std_prob$RSD <- rowRsd(tmp_fv, na.rm = TRUE)
pandoc.table(is_std_prob[, c("name", "mean_abd", "sd_abd", "RSD")],
             style = "rmarkdown", caption = "*Problematic* internal standards.")

```


# Between-sample normalization

Between-sample normalization aims to remove global abundance differences between
samples due to variations in sample collection, extraction, processing and
possibly amount. The simplest approach is to normalize abundances based on the
total sum of the signal or its median. Such approaches rely however on the
self-averaging property assuming that an increase in abundances of a group of
metabolites is balanced by a decrease in abundances in another group
[@Livera:2015bo]. Also, these approaches tend to be biased by highly abundant
metabolites. Methods robust against such a bias, like the median ratio method
(MRM [@Anders:2010fu]) or the trimmed mean of M-values (TMM [@Robinson:2010dd])
used in RNAseq data normalization could be used instead. In previous analyses
these methods had however a lower performance than the simple *median scaling*
which is thus used below. As this median scaling approach tends to be biased by 
the low intensities of metabolites calculated in the gap-filling process, the
median was calculated only on the top 1000 features with highest abundances per
sample (which are assumed to have on average the same abundance in all samples).

Below we calculate normalization factors based on the the median abundance per
sample.

```{r estimate-norm-factors, echo = FALSE, message = FALSE, eval = FALSE}
## Calculate median and scaling factors
mdns <- apply(assay(res_neg, "raw_filled"), MARGIN = 2, median, na.rm = TRUE)
nf_mdn <- mdns / median(mdns)

```

```{r norm-factors-top-200, echo = TRUE, message = FALSE, eval = TRUE}
median_top_x <- function(x, top = 500) {
    idx <- order(x, decreasing = TRUE)
    median(x[idx][seq_len(top)], na.rm = TRUE)
}
mdns <- apply(assay(res_neg, "raw_filled"), MARGIN = 2,
              median_top_x, top = 1000)
nf_mdn <- mdns / median(mdns)

```

We next apply the *median scaling* normalization.

```{r normalization, echo = TRUE, message = FALSE}
## Perform normalization
assays(res_neg)$median_filled <- sweep(assay(res_neg, "raw_filled"),
                                       MARGIN = 2, nf_mdn, `/`)

```

We plot boxplots showing the data before and after between-sample normalization
to evaluate the outcome of the procedure:

```{r norm-boxplot-raw-median, fig.path = IMAGE_PATH, fig.height = 7, fig.width = 7, fig.cap = "Comparison of the boxplots before and after normalization by the median.", echo = FALSE, message = FALSE}
## Raw data_neg
par(mfrow = c(2, 1), mar = c(0.2, 4.5, 4.5, 0.5))
cols <- col_source[as.character(res_neg$source)]
## Before between-sample normalization
dobox(log2(assay(res_neg, "raw_filled")), col = paste0(cols, "ff"),
      xaxt = "n", border = paste0(cols, 60),
      main = "Before between-sample normalization")
points(colMeans(log2(assay(res_neg, "raw_filled")), na.rm = TRUE), type = "l")
grid(nx = NA, ny = NULL)

## After normalization by median
dobox(log2(assay(res_neg, "median_filled")), col = paste0(cols, "ff"),
      xaxt = "n", border = paste0(cols, 60),
      main = "After normalization by median")
points(colMeans(log2(assay(res_neg, "median_filled")), na.rm = TRUE),
       type = "l")
grid(nx = NA, ny = NULL)

```

We can now see that the median is the same across the whole range of samples,
thus concluding that this first step of normalization worked as desired.

We also generate RLA plots:

```{r norm-rla-plot, fig.path = IMAGE_PATH, fig.height = 7, fig.width = 7, fig.cap = "Comparison of RLA values before and after before and after normalization by the median.", message = FALSE, echo = FALSE}
## RLA for median normalization
par(mfrow = c(2, 1), mar = c(0.2, 4.5, 4.5, 0.5))
boxplot(xcms::rowRla(assay(res_neg, "raw_filled"), group = res_neg$source),
        cex = 0.5, pch = 16, col = col_source[as.character(res_neg$source)],
        border = paste0(col_source[as.character(res_neg$source)], 40),
        notch = TRUE, outline = FALSE, ylim = c(-7, 5),
        xaxt = "n", ylab = "RLA", main = "Before between-sample normalization")
grid(nx = NA, ny = NULL)
boxplot(xcms::rowRla(assay(res_neg, "median_filled"), group = res_neg$source),
        cex = 0.5, pch = 16, col = col_source[as.character(res_neg$source)],
        border = paste0(col_source[as.character(res_neg$source)], 40),
        notch = TRUE, outline = FALSE, ylim = c(-7, 5),
        xaxt = "n", ylab = "RLA", main = "After normalization by median")
grid(nx = NA, ny = NULL)

```

From the plot above, we can see that the normalization step performed so far
greatly helped in reducing variability, especially for the four problematic
samples.


# Within-batch normalization

Next we perform a within-batch normalization to remove potential injection order
dependent signal drifts. In order to define whether there is a similar injection
order dependent signal drift in each batch (i.e. the drift is independent of the
batch) we fit feature-wise linear models to the (log2 transformed) data of QC
samples within each batch and compare the slopes for each feature between the
batches. 

Note that the models describing the batch effect and injection dependent signal
drift is estimated on the detected peak data, i.e. prior to filling-in missing
peak data.

Within-batch normalization is useful to remove injection-order-dependent signal
drifts: these discrepancies arise in the course of the analysis because the
intensity of the signal detected by the instrument changes with time
[@Wehrens:2016ie]. While the exact reason of this drift is unknown, it seems to
affect individual features differently.
Many algorithms have been developed to solve this problem, the best choice depends
on the type of data collected: internal standards, quality control samples
(POOL), study samples or quality control metabolites [@Livera:2015bo].
For our analysis, we assume a log-linear time-dependent signal drift, thus we
have tried to fit three different subsets to the linear model `y ~ inj_idx`, to
find the better fit, based on the relative standard deviation (RSD). More
precisely, we tried to fit only the intensities of the detected features in the
POOL samples, then we tried to fit all the features of the POOL samples
(detected and filled-in) and finally we fit all the collected signals (i.e. POOL
and study samples). The best result was obtained using all the detected signals
from Pool and study samples (only detected and without the filled-ins), 
which has been therefore used for further normalizing the data. 
We also define below the variable `req_prop` to set the minimum range that the
injection indices must span to consider a fitting valid.

```{r fit-model-plate, message = FALSE, warning = FALSE, echo = TRUE}
tmp_a <- res_neg[, res_neg$batch == "2018_02/06022018"]
tmp <- log2(assay(tmp_a, "median_filled"))
tmp[is.na(assay(tmp_a, "raw"))] <- NA   # remove filled-in signal
mdls_a <- xcms:::rowFitModel(
                   y ~ inj_idx,
                   data = as.data.frame(
                           colData(tmp_a)),
                   y = tmp,
                   method = "lm",
                   minVals = 60)
req_prop <- 3/4

```

```{r fit-model-plate 2, message = FALSE, warning = FALSE, echo = FALSE}
tmp_b <- res_neg[, res_neg$batch == "2018_02/07022018"]
tmp <- log2(assay(tmp_b, "median_filled"))
tmp[is.na(assay(tmp_b, "raw"))] <- NA
mdls_b <- xcms:::rowFitModel(
                   y ~ inj_idx,
                   data = as.data.frame(
                          colData(tmp_b)),
                   y = tmp,
                   method = "lm",
                   minVals = 60)
req_prop <- 3/4

```

We next compare the slopes from the fitted linear models for each feature
between the two batches.

```{r estimate-slopes-per-batch, message = FALSE, warning = FALSE, fig.path = IMAGE_PATH, fig.cap = "Plot of per-feataure estimates for the injection order dependent signal drift from the two batches.", fig.width = 6, fig.height = 6, echo = FALSE}

## Calculate slopes for
slps_a <- vapply(mdls_a, function(z) {
    if (length(z) > 1) {
        coefficients(z)[2]
    } else NA_real_
}, numeric(1))

slps_b <- vapply(mdls_b, function(z) {
    if (length(z) > 1) {
        coefficients(z)[2]
    } else NA_real_
}, numeric(1))

plot(slps_a, slps_b, pch = 16, col = "#00000040", xlab = "batch 1",
     ylab = "batch 2", main = "slopes")
grid()
lmod <- lm(slps_a ~ slps_b)
abline(lmod, lty = 2)

```

Not unexpectedly, there is only a relatively low correlation of the slopes 
between the batches suggesting that the injection dependent signal drift is for 
the most part batch dependent.

We next *flag* and remove fitted models we consider potentially problematic. In
particular, we remove models that were fitted to data points not spanning most
of the injection index range (e.g. models that were fitted to values with
injection indices from 1 to 20 or similar). In this case, we set `req_prop` to 
`r req_prop`, meaning that the injection range of the signals used in the 
fitting must span at least `r req_prop * 100`% of the total injection range; 
the models for which this is not valid will be then removed.

```{r}
## Calculating flags
flgs_inj_range_a <- vapply(mdls_a, flag_model_inj_range, logical(1),
                         min_range = diff(range(tmp_a$inj_idx)) * req_prop)
flgs_inj_range_b <- vapply(mdls_b, flag_model_inj_range, logical(1),
                         min_range = diff(range(tmp_b$inj_idx)) * req_prop)
```

Next, we calculate the slopes for each fitting and plot their distribution; we
highlight in blue the models of features that will be excluded based on the
criteria discussed above.

```{r within-norm-slope-dist, fig.path = IMAGE_PATH, fig.height = 5, fig.width = 5 * phi, fig.cap = "Distribution of slopes.", message = FALSE, echo = FALSE}
## Plot the distribution of slopes.
par(mfrow = c(1, 2), mar = c(4, 4.5, 1, 0.5))
hist(slps_a, breaks = 128, xlab = "slope", main = "Distribution of slopes")
if (any(flgs_inj_range_a, na.rm = TRUE))
    hist(slps_a[which(flgs_inj_range_a)], breaks = 128, add = TRUE,
         col = "#0000ff80")
abline(v = 0)
hist(slps_b, breaks = 128, xlab = "slope", main = "Distribution of slopes")
abline(v = 0)
if (any(flgs_inj_range_b, na.rm = TRUE))
    hist(slps_b[which(flgs_inj_range_b)], breaks = 128, add = TRUE,
         col = "#0000ff80")
## Split into excluded and good mdls
mdls_inj_range_a <- mdls_a[which(flgs_inj_range_a)]
mdls_inj_range_b <- mdls_b[which(flgs_inj_range_b)]
## Remove model fits for the flagged friends.
mdls_a[unique(which(flgs_inj_range_a))] <- NA
slps_a[unique(which(flgs_inj_range_a))] <- NA
mdls_b[unique(which(flgs_inj_range_b))] <- NA
slps_b[unique(which(flgs_inj_range_b))] <- NA

```

TODO: describe. also, why do we have here slightly positive slopes?

Most of the slopes, that represent the estimated injection order-dependent
signal drift, are close to 0 suggesting most features not being affected by this
bias. Most of the models have positive slopes, compared to the slightly negative
slopes we saw in positive polarity mode.

The table below lists the number of features for which the model was fitted and
the number of features for which model fitting was skipped or discarded.

```{r fit-model-table, message = FALSE, echo = FALSE, results = "asis"}
tab <- cbind(batch_a = c(length(mdls_a),
                         length(which(flgs_inj_range_a)),
                         sum(!is.na(mdls_a))),
             batch_b = c(length(mdls_b),
                         length(which(flgs_inj_range_b)),
                         sum(!is.na(mdls_b)))
             )
rownames(tab) <- c("total features", "low inj idx range",
                   "valid model fits")
cptn <- paste("Numbers of features for which an injection index dependent",
              "model could be fitted.")
pandoc.table(tab, style = "rmarkdown", caption = cptn)

```

Most of the slopes from the models describing the injection dependent signal
drift are close to 0 suggesting only a relatively low influence.

Next, we compute and visually inspect the plots of the 20 features with the
largest slopes per batch.

```{r features-large-slopes-plots, echo = FALSE, message = FALSE, warning = FALSE}
## Plotting all features with an absolute slope larger than some value.
## Plots are created but not displayed here.
## Features with absolute slope > 0.025
plot_feature <- function(x, y, model, ...) {
  plot(x, y, ...)
  if (length(model) > 1)
    abline(model)
  grid()
}
plot_slopes <- function(x, y, assay = "median_filled", fileSuffix = "") {
    for (ft in fts) {
        png(paste0(dr, ft, fileSuffix, ".png"), width = 14, height = 7,
            pointsize = 4, res = 200, units = "cm")
        plot_feature(x = seq_len(ncol(x)),
                     y = log2(assay(x, assay)[ft, ]),
                     model = y[[ft]],
                     pch = ifelse(is.na(assay(x, "raw")[ft, ]),
                                  yes = 1, no = 16),
                     col = paste0(col_source[as.character(x$source)], 80),
                     main = ft, xaxt = "n", xlab = "",
                     ylab = expression(log[2]~abundance),
                     cex = 1.8)
        dev.off()
    }
}
dr <- paste0(IMAGE_PATH, "largest_slopes_a/")
dir.create(dr, showWarnings = FALSE)
fts <- names(sort(abs(slps_a), decreasing = TRUE))[1:20]
plot_slopes(tmp_a, mdls_a)
dr <- paste0(IMAGE_PATH, "largest_slopes_b/")
dir.create(dr, showWarnings = FALSE)
fts <- names(sort(abs(slps_b), decreasing = TRUE))[1:20]
plot_slopes(tmp_b, mdls_b)

```

TODO: discuss once we're ~ OK with results.

```{r features-large-r-squared, echo = FALSE, message = FALSE, warning = FALSE}
#' Plot features with largest or smallest R squared.

#' Calculate adjusted R squared
adjr_a <- vapply(mdls_a, function(z) {
    if (length(z) > 1)
        summary(z)$adj.r.squared
    else NA_real_
}, numeric(1))
adjr_b <- vapply(mdls_b, function(z) {
    if (length(z) > 1)
        summary(z)$adj.r.squared
    else NA_real_
}, numeric(1))


#' Features with poor R2
fts <- names(sort(abs(adjr_a)))[1:20]
dr <- paste0(IMAGE_PATH, "lowest_R_batch_a/")
dir.create(dr, showWarnings = FALSE)
plot_slopes(tmp_a, mdls_a)

fts <- names(sort(abs(adjr_b)))[1:20]
dr <- paste0(IMAGE_PATH, "lowest_R_batch_b/")
dir.create(dr, showWarnings = FALSE)
plot_slopes(tmp_b, mdls_b)

#' Features with very good R2
fts_a <- names(sort(abs(adjr_a), decreasing = TRUE))[1:20]
dr <- paste0(IMAGE_PATH, "highest_R_batch_a/")
dir.create(dr, showWarnings = FALSE)
fts <- fts_a
plot_slopes(tmp_a, mdls_a)
fts_b <- names(sort(abs(adjr_b), decreasing = TRUE))[1:20]
dr <- paste0(IMAGE_PATH, "highest_R_batch_b/")
dir.create(dr, showWarnings = FALSE)
fts <- fts_b
plot_slopes(tmp_b, mdls_b)
#' Mostly fits to data in a single matrix
```

Some examples for nice model fits for features with large injection order
dependent drifts are shown below.

```{r out.width = "750px", echo = FALSE}
knitr::include_graphics(paste0(IMAGE_PATH, "highest_R_batch_a/",
                               fts_a[1], ".png"))
```

```{r out.width = "750px", echo = FALSE}
knitr::include_graphics(paste0(IMAGE_PATH, "highest_R_batch_b/",
                              fts_b[1], ".png"))

```

Next we apply the within batch correction adjusting all feature abundances (also
filled-in and imputed values) based on the estimated models. Adjustment resulted
in measurements with negative (log2) abundances. These were replaced by half
of the minimum non negative intensity for that feature. Note however that quite
some log2 abundances are smaller than 1, which represents negative intensities
in natural scale.

```{r apply-within-batch-adjustment, message = FALSE, warning = FALSE}
#' Applying the adjustment to the full (filled-in) data.
tmp <- assay(res_neg, "median_filled")
norm_before <- tmp
tmp[, colnames(tmp_a)] <- xcms:::applyModelAdjustment(
                             y = log2(assay(tmp_a, "median_filled")),
                             lmod = mdls_a,
                             data = as.data.frame(colData(tmp_a)),
                             shiftNegative = "replaceHalfMin")
tmp[, colnames(tmp_b)] <- xcms:::applyModelAdjustment(
                               y = log2(assay(tmp_b, "median_filled")), 
                               lmod = mdls_b,
                               data = as.data.frame(colData(tmp_b)),
                               shiftNegative = "replaceHalfMin")
assays(res_neg)$within_filled <- 2^tmp
tmp[is.na(assay(res_neg, "raw"))] <- NA
assays(res_neg)$within_nofill <- 2^tmp

rm(tmp)
```


# Between-batch normalization

As a last step we perform a per-feature between-batch normalization. This
normalization is based on the average abundance of the feature in the QC Pool
samples, which should be the same in both batches. Intensities of each feature
are thus adjusted to ensure that.

```{r, message = FALSE, warning = FALSE}
tmp_pool <- res_neg[, res_neg$sample == "POOL"]
mdls_batch <- xcms:::rowFitModel(y ~ batch,
                                 data = as.data.frame(colData(tmp_pool)),
                                 y = log2(assay(tmp_pool, "within_nofill")),
                                 method = "lm", minVals = 10)
```

We remove model fits that are based on less than 4 values per batch.

```{r}
#' Flag models for features with less than 6 values per batch.
flags_cat_count <- vapply(mdls_batch, flag_model_cat_count, logical(1),
                          variable = "batch", min_count = 4)
mdls_batch[which(flags_cat_count)] <- NA
```

Next we remove additional potentially problematic model fits. We evaluate for
each feature if the difference between the average concentration within a matrix
to the sample pool differs between the two batches. It would be highly
problematic to adjust such features based on the sample pools because artificial
variance would be introduced. 

Levels for pooled and study samples are about the same in the first batch while
abundances of the sample pools are much higher than most abundances in study
samples for the second batch. Normalizing this feature by per-batch averaged
abundances of pooled samples would hence artificially increase the differences
of the abundances between the batches. We thus below identify such features by
comparing the within-batch average abundance in the sample pool to the study
samples and flag features for which these are more than 2-fold different for at
least two study sample groups between the two batches.

```{r}
tmp_a <- res_neg[, res_neg$batch == levels(res_neg$batch)[1L]]
tmp_b <- res_neg[, res_neg$batch == levels(res_neg$batch)[2L]]

## calculate differences for each source to the pool
mdls_a <- xcms:::rowFitModel(y ~ source,
                             data = as.data.frame(colData(tmp_a)),
                             y = log2(assay(tmp_a, "within_filled")),
                             method = "lm", minVals = 4)
coefs_a <- t(vapply(mdls_a, function(z) {
    if (length(z) > 1) {
        coefficients(z)[c("sourcecapillary", "sourceplasma",
                          "sourceRBC", "sourcevenous")]
    } else rep(NA_real_, 4)
}, numeric(4)))

mdls_b <- xcms:::rowFitModel(y ~ source,
                             data = as.data.frame(colData(tmp_b)),
                             y = log2(assay(tmp_b, "within_filled")),
                             method = "lm", minVals = 4)
coefs_b <- t(vapply(mdls_b, function(z) {
    if (length(z) > 1) {
        coefficients(z)[c("sourcecapillary", "sourceplasma",
                          "sourceRBC", "sourcevenous")]
    } else rep(NA_real_, 4)
}, numeric(4)))

## Calculate the difference of these relative differences between the batches
coefs <- coefs_a - coefs_b

## Flagging models for which the sample-matrix relative difference to the pool
## differs between batches
flags_relative_diff <- which(rowSums(abs(coefs) > 1, na.rm = TRUE) >= 2)
```

```{r, echo = FALSE, warning = FALSE}
## Plotting the 20 features with largest difference
tmp <- rowSums(abs(coefs))
fts <- names(sort(tmp, decreasing = TRUE))[1:100]
dr <- paste0(IMAGE_PATH, "largest_difference_batch/")
dir.create(dr, showWarnings = FALSE)
plot_slopes(res_neg, mdls_batch, assay = "within_filled")

```

The table below lists the number of valid model fits.

```{r, results = "asis", echo = FALSE}
tab <- rbind(`total features ` = length(mdls_batch),
             `less than 4 values` = length(which(flags_cat_count)),
             `large relative diff to pool` = length(flags_relative_diff),
             `valid models` = sum(!is.na(mdls_batch)))
colnames(tab) <- "count"
pandoc.table(tab, style = "rmarkdown", caption = "Number of valid model fits.")
```

We next evaluate the distribution of slopes and individual plots for features
with the highest slopes.

```{r}
slps_batch <- vapply(mdls_batch, function(z) {
    if (length(z) > 1) {
        coefficients(z)[2]
    } else NA_real_
}, numeric(1))
```

We now have a look at the distribution of the slopes:

```{r between-norm-slope-dist, fig.path = IMAGE_PATH, fig.height = 5, fig.width = 5 * phi, fig.cap = "Distribution of slopes.", message = FALSE, echo = FALSE}

## Plot the distribution of slopes.
par(mar = c(4, 4.5, 1, 0.5))
hist(slps_batch, breaks = 128, xlab = "slope", main = "Distribution of slopes")
if (length(flags_relative_diff))
    hist(slps_batch[flags_relative_diff], breaks = 128, add = TRUE,
         col = "#0000ff40")
abline(v = 0)

mdls_batch[flags_relative_diff] <- NA
slps_batch[flags_relative_diff] <- NA
```


```{r features-large-slopes-plots between-batch-normalisation, echo = FALSE, message = FALSE, warning = FALSE}
dr <- paste0(IMAGE_PATH, "largest_slopes_bbn/")
dir.create(dr, showWarnings = FALSE)
fts <- names(sort(abs(slps_batch), decreasing = TRUE))[1:20]

plot_slopes(res_neg, mdls_batch, assay = "within_filled")

```



```{r between-batch-normalize, warning = FALSE, message = FALSE}
tmp <- 2^xcms:::applyModelAdjustment(
                    y = log2(assay(res_neg, "within_filled")),
                    data = as.data.frame(colData(res_neg)),
                    lmod = mdls_batch,
                    shiftNegative = "replaceHalfMin")
assays(res_neg)$normalized_filled <- tmp
tmp[is.na(assay(res_neg, "raw"))] <- NA
assays(res_neg)$normalized_nofill <- tmp
rm(tmp)
```


# Final evaluation

We compare now the performances of the normalization steps, first plotting the
distribution of signal intensities of the filled-in raw data, the median-scaled
data and the normalized data.

Evaluation of the normalization performance can be done using different
samples/measurements of the present data set:
- sample pool (QC): the same sample measured repeatedly across the data
  set. Because it is a pool of all study sample it is an ideal *general
  representation* of the whole experiment. For the present data set, however,
  different sample matrices are used (plasma, whole blood, blood cell content)
  and hence the sample pool might not be *representative* for the whole data
  set. Also, if e.g. the injection order dependent signal drift is estimated on
  these pooled samples evaluating the performance of this normalization on them
  leads to biased (overly optimistic) performance indicators.
- internal standards: represent a set of artificial compounds added (in the same
  concentration) to each sample before sample preparation. For the present data
  set IS were added to the solvent solution in which the sample was solved from
  the Mitra tips. Hence, they do not allow to evaluate and compare the whole
  sample processing procedure (sampling) and would also not allow to detect
  differences in sample amount.
- replicated measurements: the same sample measured two or more times in an
  experiment. In the present data set two separate Mitras were collected from
  each original sample. These were processed and measured separately (within the
  same batch). Normalization should thus reduce any differences in feature
  abundances between these replicated measurements.

In this section we evaluate the performance of the individual normalization
steps using the above mentioned samples. As tools to evaluate the performance we
use the coefficient of variation (CV, also called relative standard deviation
RSD) which allows to estimate the variance of a feature's signal across
replicated measurements (across sample pools are for internal standards across
all samples). To evaluate differences between replicated samples we use the
Pearson's correlation coefficient and the 90% quantile of (log2) abundance
differences. Prior to the evaluation of the normalization performance we inspect
also the clustering of samples (and QCs) before and after normalization using
principal component analysis (PCA).

```{r PCA-raw-normalized, fig.path = IMAGE_PATH, fig.width = 9, fig.height = 9, fig.cap = "PCA of raw and normalized feature abundances. Circles and rectangles indicate sample different batches.", echo = FALSE}
## Perform data imputation for PCA
assays(res_neg)$normalized_filled_imputed <-
                  imputeRowMinRand(assay(res_neg, "normalized_filled"),
                                   method = "from_to")
assays(res_neg)$raw_filled_imputed <-
                  imputeRowMinRand(assay(res_neg, "raw_filled"),
                                   method = "from_to")

pc_raw <- prcomp(t(log2(assay(res_neg, "raw_filled_imputed"))),
                 scale = FALSE, center = TRUE)
pc_norm <- prcomp(t(log2(assay(res_neg, "normalized_filled_imputed"))),
                  scale = FALSE, center = TRUE)

pch <- rep(21, ncol(res_neg))
pch[res_neg$batch == "2018_02/07022018"] <- 22
par(mfrow = c(2, 2), mar = c(4, 4, 1, 0.5))
plot_pca(pc_raw, bg = paste0(col_source[as.character(res_neg$source)], 80),
         pc_x = 1, pc_y = 2, main = "raw data", pch = pch, col = "#00000080")
legend("topleft", col = col_source, legend = names(col_source), pch = 16,
       cex = 0.4)
plot_pca(pc_raw, bg = paste0(col_source[as.character(data_neg$source)], 80),
         pc_x = 3, pc_y = 4, main = "raw data", pch = pch, col = "#00000080")
plot_pca(pc_norm, bg = paste0(col_source[as.character(res_neg$source)], 80),
         pc_x = 1, pc_y = 2, main = "normalized data",
         pch = pch, col = "#00000080")
plot_pca(pc_norm, bg = paste0(col_source[as.character(data_neg$source)], 80),
         pc_x = 3, pc_y = 4, main = "normalized data",
         pch = pch, col = "#00000080")

```

```{r PCA-raw-normalized-POOL, fig.path = IMAGE_PATH, fig.width = 9, fig.height = 9, fig.cap = "PCA of raw and normalized feature abundances for pooled samples. Circles and rectangles indicate sample different batches.", echo = FALSE}
## Perform data imputation for PCA
tmp_pool <- res_neg[, res_neg$source == "all"]

pc_raw_pool <- prcomp(t(log2(assay(tmp_pool, "raw_filled_imputed"))),
                 scale = FALSE, center = TRUE)
pc_norm_pool <- prcomp(t(log2(assay(tmp_pool, "normalized_filled_imputed"))),
                  scale = FALSE, center = TRUE)

pch <- rep(21, ncol(res_neg))
pch[tmp_pool$batch == "2018_02/07022018"] <- 22
par(mfrow = c(2, 2), mar = c(4, 4, 1, 0.5))
plot_pca(pc_raw_pool, bg = paste0(col_source[as.character(tmp_pool$source)], 80),
         pc_x = 1, pc_y = 2, main = "raw data, pool",
         pch = pch, col = "#00000080")
legend("topleft", col = col_source, legend = names(col_source), pch = 16,
       cex = 0.4)
plot_pca(pc_raw_pool, bg = paste0(col_source[as.character(tmp_pool$source)], 80),
         pc_x = 3, pc_y = 4, main = "raw data, pool",
         pch = pch, col = "#00000080")
plot_pca(pc_norm_pool, bg = paste0(col_source[as.character(tmp_pool$source)], 80),
         pc_x = 1, pc_y = 2, main = "normalized data, pool",
         pch = pch, col = "#00000080")
plot_pca(pc_norm_pool, bg = paste0(col_source[as.character(tmp_pool$source)], 80),
         pc_x = 3, pc_y = 4, main = "normalized data, pool",
         pch = pch, col = "#00000080")

```


```{r PCA-raw-normalized-plasma, fig.path = IMAGE_PATH, fig.width = 9, fig.height = 9, fig.cap = "PCA of raw and normalized feature abundances for plasma samples. Circles and rectangles indicate sample different batches.", echo = FALSE}
## Perform data imputation for PCA
tmp_plasma <- res_neg[, res_neg$source == "plasma"]

pc_raw_plasma <- prcomp(t(log2(assay(tmp_plasma, "raw_filled_imputed"))),
                 scale = FALSE, center = TRUE)
pc_norm_plasma <- prcomp(t(log2(assay(tmp_plasma, "normalized_filled_imputed"))),
                  scale = FALSE, center = TRUE)

pch <- rep(21, ncol(res_neg))
pch[tmp_plasma$batch == "2018_02/07022018"] <- 22
par(mfrow = c(2, 2), mar = c(4, 4, 1, 0.5))
plot_pca(pc_raw_plasma, bg = paste0(col_source[as.character(tmp_plasma$source)], 80),
         pc_x = 1, pc_y = 2, main = "raw data, plasma",
         pch = pch, col = "#00000080")
legend("topleft", col = col_source, legend = names(col_source), pch = 16,
       cex = 0.4)
plot_pca(pc_raw_plasma, bg = paste0(col_source[as.character(tmp_plasma$source)], 80),
         pc_x = 3, pc_y = 4, main = "raw data, plasma",
         pch = pch, col = "#00000080")
plot_pca(pc_norm_plasma, bg = paste0(col_source[as.character(tmp_plasma$source)], 80),
         pc_x = 1, pc_y = 2, main = "normalized data, plasma",
         pch = pch, col = "#00000080")
plot_pca(pc_norm_plasma, bg = paste0(col_source[as.character(tmp_plasma$source)], 80),
         pc_x = 3, pc_y = 4, main = "normalized data, plasma",
         pch = pch, col = "#00000080")

```


```{r PCA-raw-normalized-venous, fig.path = IMAGE_PATH, fig.width = 9, fig.height = 9, fig.cap = "PCA of raw and normalized feature abundances for venous blood samples. Circles and rectangles indicate sample different batches.", echo = FALSE}
## Perform data imputation for PCA
tmp_venous <- res_neg[, res_neg$source == "venous"]

pc_raw_venous <- prcomp(t(log2(assay(tmp_venous, "raw_filled_imputed"))),
                 scale = FALSE, center = TRUE)
pc_norm_venous <- prcomp(t(log2(assay(tmp_venous, "normalized_filled_imputed"))),
                  scale = FALSE, center = TRUE)

pch <- rep(21, ncol(res_neg))
pch[tmp_venous$batch == "2018_02/07022018"] <- 22
par(mfrow = c(2, 2), mar = c(4, 4, 1, 0.5))
plot_pca(pc_raw_venous, bg = paste0(col_source[as.character(tmp_venous$source)], 80),
         pc_x = 1, pc_y = 2, main = "raw data, venous",
         pch = pch, col = "#00000080")
legend("topleft", col = col_source, legend = names(col_source), pch = 16,
       cex = 0.4)
plot_pca(pc_raw_venous, bg = paste0(col_source[as.character(tmp_venous$source)], 80),
         pc_x = 3, pc_y = 4, main = "raw data, venous",
         pch = pch, col = "#00000080")
plot_pca(pc_norm_venous, bg = paste0(col_source[as.character(tmp_venous$source)], 80),
         pc_x = 1, pc_y = 2, main = "normalized data, venous",
         pch = pch, col = "#00000080")
plot_pca(pc_norm_venous, bg = paste0(col_source[as.character(tmp_venous$source)], 80),
         pc_x = 3, pc_y = 4, main = "normalized data, venous",
         pch = pch, col = "#00000080")

```


```{r PCA-raw-normalized-capillary, fig.path = IMAGE_PATH, fig.width = 9, fig.height = 9, fig.cap = "PCA of raw and normalized feature abundances for capillary blood samples. Circles and rectangles indicate sample different batches.", echo = FALSE}
## Perform data imputation for PCA
tmp_capillary <- res_neg[, res_neg$source == "capillary"]

pc_raw_capillary <- prcomp(t(log2(assay(tmp_capillary, "raw_filled_imputed"))),
                 scale = FALSE, center = TRUE)
pc_norm_capillary <- prcomp(t(log2(assay(tmp_capillary, "normalized_filled_imputed"))),
                  scale = FALSE, center = TRUE)

pch <- rep(21, ncol(res_neg))
pch[tmp_capillary$batch == "2018_02/07022018"] <- 22
par(mfrow = c(2, 2), mar = c(4, 4, 1, 0.5))
plot_pca(pc_raw_capillary, bg = paste0(col_source[as.character(tmp_capillary$source)], 80),
         pc_x = 1, pc_y = 2, main = "raw data, capillary",
         pch = pch, col = "#00000080")
legend("topleft", col = col_source, legend = names(col_source), pch = 16,
       cex = 0.4)
plot_pca(pc_raw_capillary, bg = paste0(col_source[as.character(tmp_capillary$source)], 80),
         pc_x = 3, pc_y = 4, main = "raw data, capillary",
         pch = pch, col = "#00000080")
plot_pca(pc_norm_capillary, bg = paste0(col_source[as.character(tmp_capillary$source)], 80),
         pc_x = 1, pc_y = 2, main = "normalized data, capillary",
         pch = pch, col = "#00000080")
plot_pca(pc_norm_capillary, bg = paste0(col_source[as.character(tmp_capillary$source)], 80),
         pc_x = 3, pc_y = 4, main = "normalized data, capillary",
         pch = pch, col = "#00000080")

```


```{r PCA-raw-normalized-RBC, fig.path = IMAGE_PATH, fig.width = 9, fig.height = 9, fig.cap = "PCA of raw and normalized feature abundances for RBC. Circles and rectangles indicate sample different batches.", echo = FALSE}
## Perform data imputation for PCA
tmp_rbc <- res_neg[, res_neg$source == "RBC"]

pc_raw_rbc <- prcomp(t(log2(assay(tmp_rbc, "raw_filled_imputed"))),
                 scale = FALSE, center = TRUE)
pc_norm_rbc <- prcomp(t(log2(assay(tmp_rbc, "normalized_filled_imputed"))),
                  scale = FALSE, center = TRUE)

pch <- rep(21, ncol(res_neg))
pch[tmp_rbc$batch == "2018_02/07022018"] <- 22
par(mfrow = c(2, 2), mar = c(4, 4, 1, 0.5))
plot_pca(pc_raw_rbc, bg = paste0(col_source[as.character(tmp_rbc$source)], 80),
         pc_x = 1, pc_y = 2, main = "raw data, RBC", pch = pch, col = "#00000080")
legend("topleft", col = col_source, legend = names(col_source), pch = 16,
       cex = 0.4)
plot_pca(pc_raw_rbc, bg = paste0(col_source[as.character(tmp_rbc$source)], 80),
         pc_x = 3, pc_y = 4, main = "raw data, RBC", pch = pch, col = "#00000080")
plot_pca(pc_norm_rbc, bg = paste0(col_source[as.character(tmp_rbc$source)], 80),
         pc_x = 1, pc_y = 2, main = "normalized data, RBC",
         pch = pch, col = "#00000080")
plot_pca(pc_norm_rbc, bg = paste0(col_source[as.character(tmp_rbc$source)], 80),
         pc_x = 3, pc_y = 4, main = "normalized data, RBC",
         pch = pch, col = "#00000080")

```


```{r PCA-raw-normalized-IS, fig.path = IMAGE_PATH, fig.width = 9, fig.height = 9, fig.cap = "PCA of raw and normalized feature abundances for internal standards. Circles and rectangles indicate sample different batches.", echo = FALSE}
pc_raw <- prcomp(
    t(log2(assay(res_neg, "raw_filled_imputed")[is_std$feature_id, ])),
    scale = FALSE, center = TRUE)
pc_norm <- prcomp(
    t(log2(assay(res_neg, "normalized_filled_imputed")[is_std$feature_id, ])),
    scale = FALSE, center = TRUE)

pch <- rep(21, ncol(res_neg))
pch[res_neg$batch == "2018_02/07022018"] <- 22
par(mfrow = c(2, 2), mar = c(4, 4, 1, 0.5))
plot_pca(pc_raw, bg = paste0(col_source[as.character(res_neg$source)], 80),
         pc_x = 1, pc_y = 2, main = "raw data IS", pch = pch, col = "#00000080")
legend("bottomleft", col = col_source, legend = names(col_source), pch = 16,
       cex = 0.4)
plot_pca(pc_raw, bg = paste0(col_source[as.character(data_neg$source)], 80),
         pc_x = 3, pc_y = 4, main = "raw data IS", pch = pch, col = "#00000080")
plot_pca(pc_norm, bg = paste0(col_source[as.character(res_neg$source)], 80),
         pc_x = 1, pc_y = 2, main = "normalized data IS",
         pch = pch, col = "#00000080")
plot_pca(pc_norm, bg = paste0(col_source[as.character(data_neg$source)], 80),
         pc_x = 3, pc_y = 4, main = "normalized data IS",
         pch = pch, col = "#00000080")

```

- TODO: discuss these in the next team meeting (get feedback from Nikola?)


```{r boxplot-after-within-normalization, fig.path = IMAGE_PATH, fig.height = 10, fig.width = 8, fig.cap = "Comparison between abundances (log2) of raw data, median-scaled data and normalized data.", message = FALSE, echo = FALSE}
##Raw data
par(mfrow = c(4, 1), mar = c(0.2, 4.5, 4.5, 0.5))
cols <- col_source[as.character(res_neg$source)]
dobox(log2(assay(res_neg, "raw_filled")), col = paste0(cols, "ff"),
      xaxt = "n", border = paste0(cols, 60), main = "Raw data")
points(colMeans(log2(assay(res_neg, "raw_filled")), na.rm = TRUE), type = "l")
grid(nx = NA, ny = NULL)
## Median normalized
dobox(log2(assay(res_neg, "median_filled")), col = paste0(cols, "ff"),
      xaxt = "n", border = paste0(cols, 60), main = "Median-scaled data")
points(colMeans(log2(assay(
                     res_neg, "median_filled")), na.rm = TRUE), type = "l")
grid(nx = NA, ny = NULL)
## Within batch data
dobox(log2(assay(res_neg, "within_filled")), col = paste0(cols, "ff"),
      xaxt = "n", border = paste0(cols, 60),
      main = "Within-batch normalized data")
points(colMeans(log2(assay(res_neg, "within_filled")), na.rm = TRUE),
       type = "l")
grid(nx = NA, ny = NULL)
## Final normalized data
dobox(log2(assay(res_neg, "normalized_filled")), col = paste0(cols, "ff"),
      xaxt = "n", border = paste0(cols, 60),
      main = "Between-batch normalized data")
points(colMeans(log2(assay(res_neg, "normalized_filled")), na.rm = TRUE),
       type = "l")
grid(nx = NA, ny = NULL)


```

From the plots, we can see that most of the improvement comes from the
normalization by the median; only a few slight changes are visible after the
linear fitting.

Next, we plot the same boxplots calculated only on the *good* internal
standards:

```{r boxplot-after-within-norm-good-is, fig.path = IMAGE_PATH, fig.height = 10, fig.width = 8, fig.cap = "Comparison between abundances (log2) of raw data, median-scaled data and normalized data of Internal Standards.", message = FALSE, echo = FALSE}
##Raw data
par(mfrow = c(4, 1), mar = c(0.2, 4.5, 4.5, 0.5))
cols <- col_source[as.character(res_neg$source)]
tmp <- assay(res_neg, "raw_filled")[is_std$feature_id, ]
dobox(log2(tmp), col = paste0(cols, "ff"), notch = FALSE,
      xaxt = "n", border = paste0(cols, 60), main = "Raw data - IS")
points(colMeans(log2(tmp), na.rm = TRUE), type = "l")
grid(nx = NA, ny = NULL)
## Median normalized
tmp <- assay(res_neg, "median_filled")[is_std$feature_id, ]
dobox(log2(tmp), col = paste0(cols, "ff"), notch = FALSE,
      xaxt = "n", border = paste0(cols, 60), main = "Median-scaled data - IS")
points(colMeans(log2(tmp), na.rm = TRUE), type = "l")
grid(nx = NA, ny = NULL)
## Within batch data
tmp <- assay(res_neg, "within_filled")[is_std$feature_id, ]
dobox(log2(tmp), col = paste0(cols, "ff"), notch = FALSE,
      xaxt = "n", border = paste0(cols, 60),
      main = "Within-batch normalized data - IS")
points(colMeans(log2(tmp), na.rm = TRUE), type = "l")
grid(nx = NA, ny = NULL)
## Between batch data
tmp <- assay(res_neg, "normalized_filled")[is_std$feature_id, ]
dobox(log2(tmp), col = paste0(cols, "ff"), notch = FALSE,
      xaxt = "n", border = paste0(cols, 60),
      main = "Between-batch normalized data - IS")
points(colMeans(log2(tmp), na.rm = TRUE), type = "l")
grid(nx = NA, ny = NULL)
```

The intensities for internal standards are already highly comparable prior any
data normalization (with the exception of two blood cell samples). Normalization
(especially between sample normalization) seems to increase the variability.


Next, we plot the RLA of the whole dataset and of the internal standards to
confirm the current hypotheses:

```{r rla-after-between-normalization, fig.path = IMAGE_PATH, fig.height = 10, fig.width = 8, fig.cap = "RLA of raw data, median-scaled data and normalized data.", message = FALSE, echo = FALSE}
## Raw data
par(mfrow = c(4, 1), mar = c(0.2, 4.5, 4.5, 0.5))
boxplot(xcms::rowRla(assay(res_neg, "raw_filled"), group = res_neg$sample),
        cex = 0.5, pch = 16, col = col_source[as.character(res_neg$source)],
        border = paste0(col_source[as.character(res_neg$source)], 40),
        notch = TRUE, outline = FALSE, ylim = c(-7, 5),
        xaxt = "n", ylab = "RLA", main = "Raw data")
grid(nx = NA, ny = NULL)
## Median scaled data
boxplot(xcms::rowRla(assay(res_neg, "median_filled"), group = res_neg$sample),
        cex = 0.5, pch = 16, col = col_source[as.character(res_neg$source)],
        border = paste0(col_source[as.character(res_neg$source)], 40),
        notch = TRUE, outline = FALSE, ylim = c(-7, 5),
        xaxt = "n", ylab = "RLA", main = "Median-scaled data")
grid(nx = NA, ny = NULL)
## Within batch data
boxplot(xcms::rowRla(assay(res_neg, "within_filled"), 
                     group = res_neg$sample),
        cex = 0.5, pch = 16, col = col_source[as.character(res_neg$source)],
        border = paste0(col_source[as.character(res_neg$source)], 40),
        notch = TRUE, outline = FALSE, ylim = c(-7, 5),
        xaxt = "n", ylab = "RLA", main = "Within-batch normalized data")
grid(nx = NA, ny = NULL)
## Normalized data
boxplot(xcms::rowRla(assay(res_neg, "normalized_filled"), 
                     group = res_neg$sample),
        cex = 0.5, pch = 16, col = col_source[as.character(res_neg$source)],
        border = paste0(col_source[as.character(res_neg$source)], 40),
        notch = TRUE, outline = FALSE, ylim = c(-7, 5),
        xaxt = "n", ylab = "RLA", main = "Between-batch normalized data")
grid(nx = NA, ny = NULL)
```



```{r rla-after-within-normalization-is, fig.path = IMAGE_PATH, fig.height = 10, fig.width = 8, fig.cap = "Final RLA showing a comparison between raw data and normalized data of Internal Standards.", message = FALSE, echo = FALSE, warning = FALSE}
## Raw data
par(mfrow = c(4, 1), mar = c(1, 4.5, 4.5, 0.5))
tmp <- assay(res_neg, "raw_filled")
boxplot(xcms::rowRla(tmp[is_std$feature_id, ], group = res_neg$sample),
        cex = 0.5, pch = 16, col = col_source[as.character(res_neg$source)],
        notch = FALSE, outline = FALSE, ylim = c(-2, 1),
        xaxt = "n", ylab = "RLA", main = "Raw data - IS")
grid(nx = NA, ny = NULL)
## Median scaled data
tmp <- assay(res_neg, "median_filled")
boxplot(xcms::rowRla(tmp[is_std$feature_id, ], group = res_neg$sample),
        cex = 0.5, pch = 16, col = col_source[as.character(res_neg$source)],
        notch = FALSE, outline = FALSE, ylim = c(-2, 1),
        xaxt = "n", ylab = "RLA", main = "Median scaled - IS")
grid(nx = NA, ny = NULL)
## Within batch data
tmp <- assay(res_neg, "within_filled")
boxplot(xcms::rowRla(tmp[is_std$feature_id, ], group = res_neg$sample),
        cex = 0.5, pch = 16, col = col_source[as.character(res_neg$source)],
        notch = FALSE, outline = FALSE, ylim = c(-2, 1),
        xaxt = "n", ylab = "RLA", main = "Within-batch normalized data - IS")
grid(nx = NA, ny = NULL)
## Normalized data
tmp <- assay(res_neg, "normalized_filled")
boxplot(xcms::rowRla(tmp[is_std$feature_id, ], group = res_neg$sample),
        cex = 0.5, pch = 16, col = col_source[as.character(res_neg$source)],
        notch = FALSE, outline = FALSE, ylim = c(-2, 1),
        xaxt = "n", ylab = "RLA", main = "Between-batch normalized data - IS")
grid(nx = NA, ny = NULL)
```

From the RLA plots we can observe the same thing seen above: most changes
occurred after normalization by the median. This is also confirmed after looking
at the RLA plot of the internal standards, which exhibit a similar behaviour.
Also the RLA plots of the internal standards show an unwanted shift after
normalization. Therefore we recreated the plot only using *good* IS.

Finally, we compute the coefficient of variation (CV or relative standard
deviation RSD) for each feature in POOL and study samples, and also for internal
standards, both in POOL and study samples. We plot then boxplots and show in a
table how the RSD changes across the different groups.

```{r RSD-POOL, message = FALSE, echo = FALSE, warning = FALSE}
## Calculate RSD on all POOL signals
rsd_raw <- rowRsd(
    assay(res_neg, "raw_filled")[, res_neg$sample == "POOL"])
rsd_scl <- rowRsd(
    assay(res_neg, "median_filled")[, res_neg$sample == "POOL"])
rsd_adj <- rowRsd(
    assay(res_neg, "within_filled")[, res_neg$sample == "POOL"])
rsd_bbn <- rowRsd(
    assay(res_neg, "normalized_filled")[, res_neg$sample == "POOL"])

```

```{r RSD-study-samples, message = FALSE, echo = FALSE, warning = FALSE}
## Calculate RSD on all study samples
rsd_raw_sts <- rowRsd(
    assay(res_neg, "raw_filled")[, res_neg$sample != "POOL"])
rsd_scl_sts <- rowRsd(
    assay(res_neg, "median_filled")[, res_neg$sample != "POOL"])
rsd_adj_sts <- rowRsd(
    assay(res_neg, "within_filled")[, res_neg$sample != "POOL"])
rsd_bbn_sts <- rowRsd(
    assay(res_neg, "normalized_filled")[, res_neg$sample != "POOL"])
```

```{r RSD-internal-standards, message = FALSE, echo = FALSE, warning = FALSE}
## Calculate RSD on internal standards in POOL signals
rsd_raw_is <- rowRsd(
    assay(res_neg, "raw_filled")[is_std$feature_id, res_neg$sample == "POOL"])
rsd_scl_is <- rowRsd(
    assay(res_neg, "median_filled")[is_std$feature_id, res_neg$sample == "POOL"])
rsd_adj_is <- rowRsd(
    assay(res_neg, "within_filled")[is_std$feature_id, res_neg$sample == "POOL"])
rsd_bbn_is <- rowRsd(
    assay(res_neg, "normalized_filled")[is_std$feature_id, res_neg$sample == "POOL"])

## Calculate RSD on good internal standards in study samples
rsd_raw_is_sts <- rowRsd(
    assay(res_neg, "raw_filled")[is_std$feature_id, res_neg$sample != "POOL"])
rsd_scl_is_sts <- rowRsd(
    assay(res_neg, "median_filled")[is_std$feature_id, res_neg$sample != "POOL"])
rsd_adj_is_sts <- rowRsd(
    assay(res_neg, "within_filled")[is_std$feature_id, res_neg$sample != "POOL"])
rsd_bbn_is_sts <- rowRsd(
    assay(res_neg, "normalized_filled")[is_std$feature_id, res_neg$sample != "POOL"])

```

```{r norm-rsd-plot, fig.path = IMAGE_PATH, message = FALSE, echo = FALSE, fig.height = 7, fig.width = 7 * phi, fig.cap = "Coefficient Of Variation (RSD)."}
par(mfrow = c(2, 2))
boxplot(list(raw = rsd_raw, scaled = rsd_scl, within = rsd_adj, 
             normalized = rsd_bbn),
        main = "All signals - POOL samples")
grid(nx = NA, ny = NULL)
abline(h = 0.3)

boxplot(list(raw = rsd_raw_sts, scaled = rsd_scl_sts, within = rsd_adj_sts, 
             normalized = rsd_bbn_sts),
        main = "All signals - Study samples")
grid(nx = NA, ny = NULL)
abline(h = 0.3)

boxplot(list(raw = rsd_raw_is, scaled = rsd_scl_is, within = rsd_adj_is,
             normalized = rsd_bbn_is),
        main = "IS - POOL samples")
grid(nx = NA, ny = NULL)
abline(h = 0.3)

boxplot(list(raw = rsd_raw_is_sts, scaled = rsd_scl_is_sts,
             within = rsd_adj_is_sts, normalized = rsd_bbn_is_sts),
        main = "IS - Study samples")
grid(nx = NA, ny = NULL)
abline(h = 0.3)

```


The table below lists the results.

```{r final-qa-rsd-table, message = FALSE, echo = FALSE, results = "asis", warning = FALSE}
T <- rbind(
    `QC samples, RSD` = c(raw = mean(rsd_raw, na.rm = TRUE),
                          scaled = mean(rsd_scl, na.rm = TRUE),
                          `within-batch` = mean(rsd_adj, na.rm = TRUE),
                          `between-batch` = mean(rsd_bbn, na.rm = TRUE)),
    `study samples, RSD` = c(raw = mean(rsd_raw_sts, na.rm = TRUE),
                             scaled = mean(rsd_scl_sts, na.rm = TRUE),
                             `within-batch` = mean(rsd_adj_sts, na.rm = TRUE),
                             `between-batch` = mean(rsd_bbn_sts, na.rm = TRUE)),
    `IS QC, RSD` = c(raw = mean(rsd_raw_is, na.rm = TRUE),
                     scaled = mean(rsd_scl_is, na.rm = TRUE),
                     `within-batch` = mean(rsd_adj_is, na.rm = TRUE),
                     `between-batch` = mean(rsd_bbn_is, na.rm = TRUE)),
    `IS study, RSD` = c(raw = mean(rsd_raw_is_sts, na.rm = TRUE),
                        scaled = mean(rsd_scl_is_sts, na.rm = TRUE),
                        `within-batch` = mean(rsd_adj_is_sts, na.rm = TRUE),
                        `between-batch` = mean(rsd_bbn_is_sts, na.rm = TRUE)),
    `QC samples, %RSD > 0.3` = c(sum(rsd_raw > 0.3, na.rm = TRUE),
                                 sum(rsd_scl > 0.3, na.rm = TRUE),
                                 sum(rsd_adj > 0.3, na.rm = TRUE),
                                 sum(rsd_bbn > 0.3, na.rm = TRUE)) *
        100 / length(rsd_raw),
    `study samples, %RSD > 0.3` = c(sum(rsd_raw_sts > 0.3, na.rm = TRUE),
                                    sum(rsd_scl_sts > 0.3, na.rm = TRUE),
                                    sum(rsd_adj_sts > 0.3, na.rm = TRUE),
                                    sum(rsd_bbn_sts > 0.3, na.rm = TRUE)) *
        100 / length(rsd_raw_sts),
    `IS QC, %RSD > 0.3` = c(sum(rsd_raw_is > 0.3, na.rm = TRUE),
                            sum(rsd_scl_is > 0.3, na.rm = TRUE),
                            sum(rsd_adj_is > 0.3, na.rm = TRUE),
                            sum(rsd_bbn_is > 0.3, na.rm = TRUE)) *
        100 / length(rsd_raw_is),
    `IS study, %RSD > 0.3` = c(sum(rsd_raw_is_sts > 0.3, na.rm = TRUE),
                               sum(rsd_scl_is_sts > 0.3, na.rm = TRUE),
                               sum(rsd_adj_is_sts > 0.3, na.rm = TRUE),
                               sum(rsd_bbn_is_sts > 0.3, na.rm = TRUE)) *
        100 / length(rsd_raw_is_sts)
)
cpt <- paste0("Summary of RSD calculations. We show how the RSD changes among ",
              "different groups: all features in POOL samples, only detected ",
              "signals in POOL samples, all features in study samples, ",
              "internal standards in POOL samples and internal standards in ",
              "study samples.")
pandoc.table(T, caption = cpt, style = "rmarkdown")
```

From what we see, there is an improvement in RSD from raw to normalized data in
the POOL samples: this outcome is desired, though also biased, as we fit our
data to these signals. The RSD of study samples is, as expected, much larger
than the RSD of POOL samples. Normalization does not reduce the variance between
study samples, which is desired as any reduction might reduce also biological
variance. Unexpectedly, the RSD for internal standards is much larger in study
samples than in POOL samples.

Both, the coefficient of variation on QC samples or internal standards (IS) seem
to be not ideal to assess quality of normalization for the present data set. We
have however two *technical* replicates available for each sample. These
represents two independent Mitra tips from the same original sample
(i.e. Mitra-sampling from the finger, or same blood sample taken by phlebotomy).
Below we compare the replicated measurements reporting the intercept and slope
as well as the $R^2$ and F-statistic from a linear model fitted to the data, the
Pearson correlation coefficient between the replicated measurements and the 90%
quantile of the (log2) fold-change values. All these values are calculated on
the raw data, the median scaled and the fully normalized data and reported for
each replicate pair.

```{r}
res_neg$source_sample <- paste0(res_neg$source, "_", res_neg$sample)

#' Summary of replicated measurements:
#' - fit linear model to the replicated measurements
#' - extract coefficients (intercept and slope),  R^2 and F-statistic
#' - extract the xx quantile of the log2 fold-change value between replicated
#'   measurements
replicate_summary <- function(x, assay = "raw_filled", quantile = 0.9) {
    reps <- unique(x$source_sample)
    reps <- reps[reps != "all_POOL"]
    res <- matrix(ncol = 6, nrow = length(reps))
    for (i in seq_along(reps)) {
        idx <- which(x$source_sample == reps[i])
        if (length(idx) == 2) {
            a <- log2(assay(x, assay)[, idx[1L]])
            b <- log2(assay(x, assay)[, idx[2L]])
            lm_sum <- summary(lm(a ~ b))
            res[i, ] <- c(lm_sum$coefficients[, 1], lm_sum$r.squared,
                          lm_sum$fstatistic[1],
                          quantile(abs(a - b), quantile, na.rm = TRUE),
                          cor(a, b, use = "pairwise.complete.obs"))
        }
    }
    colnames(res) <- c("intercept", "slope", "R2", "F",
                       paste0(quantile * 100, "% log2FC"), "R")
    rownames(res) <- reps
    res
}

repl_raw <- replicate_summary(res_neg, quantile = 0.9)
repl_med <- replicate_summary(res_neg, assay = "median_filled", quantile = 0.9)
repl_within <- replicate_summary(res_neg, assay = "within_filled",
                                 quantile = 0.9)
repl_between <- replicate_summary(res_neg, assay = "normalized_filled",
                                 quantile = 0.9)
```


```{r final-eval-boxplot, echo = FALSE, fig.path = IMAGE_PATH, fig.width = 10, fig.height = 4, fig.cap = "Comparison between replicated measurements."}
par(mfrow = c(1, 2))
boxplot(cbind(raw = repl_raw[, "R"], median = repl_med[, "R"],
              within = repl_within[, "R"], normalized = repl_between[, "R"]),
        main = "R", ylab = "R")
grid(nx = NA, ny = NULL)
boxplot(cbind(raw = repl_raw[, 5], median = repl_med[, 5],
              within = repl_within[, 5], normalized = repl_between[, 5]),
        main = "90% log2FC", ylab = "90%~log2FC")
grid(nx = NA, ny = NULL)
```

```{r, echo = FALSE, results = "asis"}
## table for above
tab <- rbind(
    raw = colMeans(repl_raw[, c("R", "90% log2FC")]),
    scaled = colMeans(repl_med[, c("R", "90% log2FC")]),
    `within-batch` = colMeans(repl_within[, c("R", "90% log2FC")]),
    `between-batch` = colMeans(repl_between[, c("R", "90% log2FC")])
)
pandoc.table(t(tab), style = "rmarkdown",
             caption = "Evaluation of replicated measurements.")
```

TODO: discuss.


At last missing values were imputed and the result object saved.

```{r}
assays(res_neg)$normalized_filled_imputed <-
                  imputeRowMinRand(assay(res_neg, "normalized_filled"),
                                   method = "from_to")
save(res_neg, file = paste0(RDATA_PATH, "res_neg.RData"))
```

## Conclusion

- From the PCA analysis and also from the within and between-batch normalization
  it seems that a large batch effect seems to be present in the pooled samples
  (QC samples), which does not seem to be present in study samples.
- As a consequence, within-batch normalization was performed on all study
  samples instead of estimating the drift on pooled samples only.
- For downstream analyses we might rely on the between-sample and within-batch
  normalized data and will ignore the between-batch normalized data.


# Session information

The versions of R and the individually used packges are listed below.

```{r}
sessionInfo()
```

# References

