---
title: "Differential abundance analysis, untargeted approach"
subtitle: "Negative polarity"
author: "Christa Malfertheiner"
date: "14 July 2021"
output:
  BiocStyle::html_document:
    toc: true
    number_sections: false
    toc_float: true
bibliography: references.bib
csl: biomed-central.csl
references:
- id: dummy
  title: no title
  author:
  - family: noname
    given: noname
---

```{r setup, echo = FALSE, results = "asis", warning = FALSE}
library(BiocStyle)
BiocStyle::markdown()
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
```

```{r parameters, echo = FALSE, warning = FALSE}
## Set general parameters
polarity <- "NEG" # specify "POS" or "NEG"
p.cut <- 0.05     # cut-off for significance.
m.cut <- 0.7      # cut-off for log2 fold change

set.seed(123)

## Setting golden ratio to save images
phi <- (1+sqrt(5))/2

FILE_NAME <- "diff_analysis_untargeted_neg"

## Define paths:
IMAGE_PATH <- paste0("images/", FILE_NAME, "/")
if (dir.exists(IMAGE_PATH)) unlink(IMAGE_PATH, recursive = TRUE, force = TRUE)
dir.create(IMAGE_PATH, recursive = TRUE, showWarnings = FALSE)

RDATA_PATH <- paste0("data/RData/", FILE_NAME, "/")
dir.create(RDATA_PATH, recursive = TRUE, showWarnings = FALSE)

RESULT_PATH <- paste0("data/results/", FILE_NAME, "/")
dir.create(RESULT_PATH, recursive = TRUE, showWarnings = FALSE)
```

# Introduction

In this document we perform the differential abundance analysis of the features
previously identified for the *MitYOU* project, with the aim of identifying
significant sex-related features. This task is performed by hypothesis testing,
where we try to identify which metabolites have the most different 
concentrations between female and male samples in plasma samples, venous and
capillary blood samples. We follow an untargeted approach, the analysis comprises
feature pre-filtering, exploratory analysis and differential abundance analysis
carried out on each matrix individiously.


# Data import

First, we load the required packages and the data, after preprocessing and
normalization. The end result of these steps is a `SummarizedExperiment` that
contains aligned data, where features are grouped (after correspondence), and
that have undergone gap filling, normalization by the median, linear fitting and 
per-feature between-batch normalization to remove any unwanted variability. 
The `SummarizedExperiment` lets us store all the information regarding the 
normalization steps in the form of `assays`, which we are still able to access 
to proceed with the analysis.

```{r load-data, echo = FALSE, warning = FALSE}
library(xcms)
library(limma)
library(pheatmap)
library(writexl)
library(SummarizedExperiment)
library(RColorBrewer)
library(MsFeatures)
library(CompMetaboTools)
library(pander)

load("data/RData/differential_abundance_neg/res_neg.RData")
```

We assign the colours as seen before.
#need to remove pool or already removed by using diff_abundance file?

```{r split-qc, echo = TRUE}
res_qc <- res_neg[, res_neg$source == "all"]
res_neg <- res_neg[, res_neg$source != "all"]
res_neg$source <- factor(as.character(res_neg$source))
res_neg$sex <- factor(as.character(res_neg$sex))

col_source <- brewer.pal(5, name = "Set1")
names(col_source) <- c("RBC",           #' red
                       "plasma",        #' blue
                       "all",           #' green
                       "capillary",     #' purple
                       "venous")        #' orange

col_sex <- brewer.pal(4, name = "Set1") [c(1, 2, 3)]
names(col_sex) <- c("F",           # red
                    "M",           # blue
                    "POOL")        # green

## Setting golden ratio to save images
phi <- (1+sqrt(5))/2
```

The samples used in this analysis are listed below.

```{r, echo = FALSE, results = "asis"}
tab <- colData(res_neg)[, c("source", "sex", "age")]
pandoc.table(as.data.frame(tab), style = "rmarkdown",
             caption = "Samples used in this analysis")
```

# Feature pre-filtering

Feature pre-filtering is an important step of data analysis that aims to
reduce as much as possible the random error that occurs during the measurement
of an analyte: during this process, features with high noise and features that
were detected in a low number of samples are removed. As a side effect, by
reducing the number of features that are being tested later, the pre-filtering
reduces also the loss of power by the subsequent adjustment for multiple
hypothesis testing.

This step is fundamental, though one must be careful not to pre-filter for a
characteristic that will be tested later: the pre-filtering must be, as a matter
of fact, independent from later analyses.

The first step of pre-filtering consists of removing features with high
technical variance; several methods have been developed to determine which
signals must be removed, the most common of which relies on the **relative
standard deviation (RSD)**, which is defined as the ratio between the standard
deviation and the mean:

$RSD = \dfrac{s_{i,qc}}{\bar{m}_{i,qc}}$

This value is calculated for each feature found in the pooled QC samples: when
this is higher than 30%, the feature is removed from the dataset
[@broadhurstGuidelinesConsiderationsUse2018].

Another common approach is based on the **dispersion ratio (D-ratio)**: this is
defined as the ratio between the sample standard deviation for the pooled QC
samples and the sample standard deviation for the study samples (the former
expected to represent technical variance, the latter a combination of technical
and biological variance):

$D-ratio = \dfrac{s_{i,qc}}{s_{i,sample}}$

The interpretation of this value goes as follows: when the D-ratio is 0%, there
is no technical variance in the observed measurements, whereas a D-ratio of
100% represents only noise and no biological variance detected. A common cut-off
for the D-ratio is 0.5, aiming at keeping features whose variation in study
samples is twice as large as the one in QC samples
[@broadhurstGuidelinesConsiderationsUse2018]. For the present dataset we should
calculate the D-ratio **separately** for each source (sample matrix) because the
variance between sample matrices is expected to be very large. For each feature
we use then the smallest D-ratio from the 4 sample matrices.

```{r filter-rsd, warning = FALSE}
rsds <- rowRsd(assay(res_qc, "normalized_filled"))
dratios_ven <- apply(
    log2(assay(res_qc, "normalized_filled")), 1, sd, na.rm = TRUE) /
    apply(log2(assay(res_neg[, res_neg$source == "venous"],
                     "normalized_filled")), 1, sd, na.rm = TRUE)
dratios_rbc <- apply(
    log2(assay(res_qc, "normalized_filled")), 1, sd, na.rm = TRUE) /
    apply(log2(assay(res_neg[, res_neg$source == "RBC"],
                     "normalized_filled")), 1, sd, na.rm = TRUE)
dratios_cap <- apply(
    log2(assay(res_qc, "normalized_filled")), 1, sd, na.rm = TRUE) /
    apply(log2(assay(res_neg[, res_neg$source == "capillary"],
                     "normalized_filled")), 1, sd, na.rm = TRUE)
dratios_pla <- apply(
    log2(assay(res_qc, "normalized_filled")), 1, sd, na.rm = TRUE) /
    apply(log2(assay(res_neg[, res_neg$source == "plasma"],
                     "normalized_filled")), 1, sd, na.rm = TRUE)
dratios <- apply(cbind(dratios_ven, dratios_rbc, dratios_cap, dratios_pla),
                 MARGIN = 1, min, na.rm = TRUE)
dratios[is.infinite(dratios)] <- NA
```

The distribution of RSD values and D-ratio is shown in the plot below:

```{r filter-rsd-plot, fig.path = IMAGE_PATH, fig.width = 5 * phi, fig.height = 5, fig.cap = "Distribution of RSD values and D-ratios in the data set. The dashed vertical red line represents the cut-off value for the RSD and D-ratio, respectively.", echo = FALSE}
par(mfrow = c(1, 2))
plot(density(rsds, na.rm = TRUE), xlab = "RSD",
     main = "Distribution of RSD values")
abline(v = 0.3, col = "red", lty = 2)
plot(density(dratios, na.rm = TRUE), xlab = "D-ratio",
     main = "Distribution of D-ratios")
abline(v = 0.5, col = "red", lty = 2)
```

The plot below directly compares the RSD and D-ratio for each feature.

```{r filter-rsd-vs-dratio-plot, fig.path = IMAGE_PATH, fig.width = 5, fig.height = 5, fig.cap = "Direct comparison of RSD and D-ratios.", echo = FALSE}
plot(log2(rsds), log2(dratios), xlab = expression(log[2]~RSD),
     ylab = expression(log[2]~D-ratio), pch = 16, col = "#00000040")
abline(v = log2(0.3), col = "red", lty = 2)
abline(h = log2(0.5), col = "red", lty = 2)
```

The plot shows a correlation between RSD and D-ratios, though the two methods
are not interchangeable. Below we pre-filter the data using the D-ratio.

```{r do-filter}
res <- res_neg[which(dratios < 0.5), ]
```

This reduced the data set from `r length(dratios)` to `r nrow(res)` features.
Next, we discard the features that have not been identified in at least 50% of
the samples in any of the sample groups.

```{r filter-proportion}
keep <- moreAreValidThan(assay(res, "raw"), f = res$source, prop = 0.3)
res <- res[keep, ]
```

The dataset has been reduced from `r length(rsds)` to `r nrow(res)` features:
this result shows that most features have been retained even after
pre-filtering, thus ensuring a dataset where features have a D-ratio lower than
0.5 and have less than 70% missing values.


# Exploratory analysis: PCA

Next, we perform a PCA analysis: this allows us to gather information about any
possible similarities among the samples, based on the measured metabolite
intensities.

```{r pca-all}
pc <- prcomp(t(log2(assay(res, "normalized_filled_imputed"))),
                 center = TRUE, scale. = FALSE)
```

```{r pca-plot, fig.path = IMAGE_PATH, fig.cap = "PCA of the samples based on feature intensities.", fig.width = 7 * phi, fig.height = 7, echo = FALSE}
par(mfrow = c(1, 2))
plot_pca(pc, col = paste0(col_source[as.character(res$source)], 90),
         pc_x = 1, pc_y = 2)
plot_pca(pc, col = paste0(col_source[as.character(res$source)], 90),
         pc_x = 3, pc_y = 4)
legend("topleft", col = col_source, legend = names(col_source),
       title = "phenotype", pch = 16, ncol = 2)
```

We see a clear separation by sample matrix. Also, a higher variability of RBC
and capillary samples is visible. All plasma samples are clustered together far
apart from the other matrices.


# Differential abundance analysis

In this section, we perform a differential abundance analysis to identify
features that have significantly different abundances between male and female 
samples. The analysis is based on feature-wise multiple linear regression:
the aim of such analysis is to find the relationship between the independent
variables (age and sex) and the response variable (signal intensity).
In short, multiple linear regression is a form of linear regression that is used
when there are two or more predictors.
Multiple linear regression is preferred over separate simple linear regression
in order to avoid wrong predictions: this could happen because the input
variables may be correlated, which could lead to unsatisfactory results. The
formula for multiple regression model is:

$Y = \beta_0 + \beta_1x_{i1} + \beta_2x_{i2} \ldots, + \beta_px_{ip} + \epsilon$

where: \
- $Y =$ predicted value (dependent variable) \
- $\beta_0 =$ y intercept, constant term
- $\beta_1, \beta_2, \ldots, \beta_p =$ regression coefficients \
- $x_i =$ independent variables \
- $\epsilon =$ residuals.

The `limma` package contains the `lmFit` function, which calculates the linear
model that best describes the data. The results are stored in a `MArrayLM`
(Microarray Linear Model Fit) object.

This model, though, is not enough to accept whether or not there is actually a
relationship among the response and the independent variables, therefore we must
perform a hypothesis test: we define the *null hypothesis* as there not being
any differences in the abundances of metabolites in male and female samples. The
*alternative hypothesis* is therefore defined when there are differences in the
intensities of the signals coming from the metabolites in the two different
experimental groups.
To accept or reject the alternative hypothesis, it is necessary to calculate the
p-value: the function that allows us to add the results to the `MArrayLM` object
created before is `eBayes`. The `eBayes` function computes several statistics,
including the moderated t-test, which is defined as follows:

$\dfrac{d}{s + s_0}$

where \
- $d =$ difference in two group means ($m_1 - m_2$) \
- $s =$ pooled standard deviation \
- $s_0 =$ small constant (it depends on the variance within the group).

The constant is added to the denominator in order to avoid a division by an
extremely low number, which would of course increase the result of the statistic
falsely inducing us into rejecting the null hypothesis, thus considering the
difference as significant, when it is not. When performing multiple hypothesis
testing, though, there is a high chance of rejecting the null hypothesis when it
is true (type I error), thus a method to control the False Discovery Rate is
required: in this case we opted for Benjamini-Hochberg correction. In
conclusion, the alternative hypothesis is rejected when the adjusted p-value is
smaller than the confidence threshold that was set at the beginning of this
document to `r p.cut`. This means we accept `r p.cut * 100`% false positives
among the features called *significant*.

```{r analysis}
## We subsample the sample sources
res_cap = res[, res$source == "capillary"]
res_ven = res[, res$source == "venous"]
res_plas = res[, res$source == "plasma"]

#We first have a look at the capillary blood samples
## Factor sample source and sex
sex <- factor(res_cap$sex)
age <- res_cap$age

## Fit the data to the desired design
dsgn <- model.matrix(~ 0 + sex)
fit <- lmFit(log2(assay(res_cap, "normalized_filled_imputed")), design = dsgn)


## Fit the actual contrasts of interest
contr_mat <- makeContrasts(
  MvsF = sexM - sexF,
  levels = dsgn)
fit <- contrasts.fit(fit, contrasts = contr_mat)
fit <- eBayes(fit)

```

The next step involves creating a data frame that contains the results obtained
in the code chunk above. Also, we determine whether or not a feature can be
considered significant based on the p-value (the adjusted p-value must be below
the threshold of `r p.cut`) and on the log2 fold change (the (absolute)
coefficients calculated with `lmFit` must be higher than `r m.cut`).

The data frame is then added to the `rowData` of the `res_cap` object.

```{r result-data-frame, echo = FALSE}
add_result <- function(x) {
    ## Generate result data frame
    tmp <- data.frame(
        coef = fit$coefficient[, "MvsF"],
        pvalue = fit$p.value[, "MvsF"],
        adjp = p.adjust(fit$p.value[, "MvsF"], method = "BH"),
        avg.M = rowMeans(
            log2(assay(x, "normalized_filled_imputed")[, x$sex == "M"])),
        avg.F = rowMeans(
            log2(assay(x, "normalized_filled_imputed")[, x$sex == "F"]))
    )
    ## Evaluate which features are significant
    tmp$significant <- abs(tmp$coef) > m.cut & tmp$adjp < p.cut
    tmp$RSD_QC <- rsds[rownames(rowData(x))]
    tmp$Dratio <- dratios[rownames(rowData(x))]
    ## Add data frame to res
    rowData(x) <- cbind(rowData(x), tmp)
    x
}

res_cap <- add_result(res_cap)
```

We plot then the distribution of p-values, both raw and adjusted.

```{r histogram, echo = FALSE, fig.path = IMAGE_PATH, fig.width = 7 * phi, fig.height = 7, fig.cap = "Distribution of raw (left) and adjusted p-values (right)."}
par(mfrow = c(1, 2))
hist(rowData(res_cap)$pvalue, breaks = 64, xlab = "p value",
     main = "Distribution of raw p-values")
hist(rowData(res_cap)$adjp, breaks = 64, xlab = expression(p[BH]~value),
     main = "Distribution of adjusted p-values")
```